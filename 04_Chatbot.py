# streamlit_rag_app.py

import os
import re
import textwrap
import html
from urllib.parse import unquote
import streamlit as st
from pathlib import Path
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


# -----------------------------
# ğŸ”§ ê¸°ë³¸ ì„¤ì •
# -----------------------------
# === ê²½ë¡œë¥¼ ìƒëŒ€ê²½ë¡œë¡œ ì„¤ì • (chatbot_repo/data) ===
try:
    BASE_DIR = Path(__file__).resolve().parent   # ì´ íŒŒì¼ì´ ìˆëŠ” í´ë” = chatbot_repo
except NameError:                                 # Jupyter ë“± __file__ì´ ì—†ì„ ë•Œ
    BASE_DIR = Path.cwd()


# Path ê°ì²´ë¡œ ê²½ë¡œ ì •ì˜
DEFAULT_CHROMA_DIR_PATH = BASE_DIR / "data"

# âœ¨âœ¨ ì´ ë¶€ë¶„ì„ ì¶”ê°€í•˜ì„¸ìš”! âœ¨âœ¨
# ./data ë””ë ‰í„°ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´, ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
# ë¶€ëª¨ ë””ë ‰í„°ë¦¬ê°€ ì—†ì–´ë„ ë§Œë“¤ì–´ì£¼ê³ (parents=True), ì´ë¯¸ ìˆì–´ë„ ì˜¤ë¥˜ë¥¼ ë‚´ì§€ ì•ŠìŠµë‹ˆë‹¤(exist_ok=True).
DEFAULT_CHROMA_DIR_PATH.mkdir(parents=True, exist_ok=True)

# ì‹¤ì œ ì‚¬ìš©í•  ë•ŒëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
DEFAULT_CHROMA_DIR = str(DEFAULT_CHROMA_DIR_PATH)

#DEFAULT_CHROMA_DIR = r"C:\Users\PC1\OneDrive\í”„ë¡œì íŠ¸\250801_ì•„ëª¨ë ˆ\chroma_db"
DEFAULT_MODEL       = "google/gemma-2-9b-it"   # 03_RAGì™€ ë™ì¼ ê³„ì—´
EMBED_MODEL_NAME    = "nlpai-lab/KURE-v1"      # 03_RAGì™€ ë™ì¼
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"

SYSTEM_PROMPT = """You are a precise RAG assistant. Use ONLY the provided context.
If the answer is not in the context, say you don't know briefly.
Answer in Korean.
"""

USER_PROMPT_TEMPLATE = """[Context]
{context}

[Question]
{question}

[Instructions]
- Keep the answer concise but complete (â‰¤ 5 sentences).
"""


# -----------------------------
# ğŸ¨ í˜ì´ì§€ ìŠ¤íƒ€ì¼
# -----------------------------
st.set_page_config(page_title="RAG Q&A", page_icon="ğŸ”", layout="wide")

CUSTOM_CSS = """
<style>
header {visibility: hidden;}
.answer-card {
  border-radius: 16px; padding: 18px 20px;
  background: #ffffff; border: 1px solid rgba(0,0,0,0.08);
  box-shadow: 0 6px 20px rgba(0,0,0,0.06);
}
.chip {
  display:inline-block; padding:4px 10px; border-radius:999px;
  background:#eef2ff; color:#3949ab; font-weight:600; font-size:12px; margin-bottom:6px;
}
.doc-card {
  border-radius: 14px; padding: 12px 14px; background:#fafafa; border:1px solid #eee; margin-bottom:12px;
}
.doc-head {font-weight:700; font-size:14px;}
.doc-body {font-size:13px; color:#333;}
.small {color:#666; font-size:12px;}
.footer {color:#777; font-size:12px; margin-top:8px;}
.stat {color:#444; font-size:13px; margin-bottom:6px;}
.history-card {
  border-radius: 12px; padding:10px 12px; background:#f6f7fb; border:1px solid #e6e8f5; margin-bottom:8px;
}
.history-q {font-weight:700; font-size:13px;}
.history-a {font-size:12px; color:#555; margin-top:4px;}
.suggest-box {margin-top:8px; padding:10px 12px; background:#f9fafb; border:1px dashed #d7dbe2; border-radius:12px;}

.doc-tags {margin:6px 0 8px 0}
.badge {display:inline-block; padding:2px 8px; border-radius:999px; background:#eef2ff; color:#3949ab; font-size:11px; margin-right:6px;}
.filepill {display:inline-block; padding:2px 8px; background:#f1f5ff; border:1px solid #dfe6ff; color:#2146b7; border-radius:8px; font-weight:600;}
.sum-list {margin:6px 0 0 0; padding-left:18px;}
.kv-table {width:100%; border-collapse:collapse; margin-top:8px; font-size:12px;}
.kv-table th, .kv-table td {border:1px solid #e9e9ef; padding:6px 8px; text-align:left;}
.kv-table th {background:#f6f7fb; font-weight:700;}
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

st.title("ğŸ” RAG Q&A")
st.caption("03_RAG íŒŒì´í”„ë¼ì¸ì„ Streamlit UIë¡œ â€” LangChain + Chroma + OpenRouter")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "history" not in st.session_state:
    st.session_state["history"] = []   # [{q, a, k, sources}]
if "retrieved_docs" not in st.session_state:
    st.session_state["retrieved_docs"] = []
if "answer" not in st.session_state:
    st.session_state["answer"] = ""
if "user_query" not in st.session_state:
    st.session_state["user_query"] = ""
if "pending_query" not in st.session_state:
    st.session_state["pending_query"] = None


# -----------------------------
# ğŸ§° ì‚¬ì´ë“œë°” (ì„¤ì • + ìµœê·¼ ê¸°ë¡)
# -----------------------------
with st.sidebar:
    st.subheader("Settings")
    chroma_dir  = st.text_input("Chroma persist directory", value=DEFAULT_CHROMA_DIR)
    top_k       = st.slider("Top-K (retrieval)", 1, 10, 3)
    temperature = st.slider("LLM Temperature", 0.0, 1.0, 0.2)
    model_name  = st.text_input("LLM (OpenRouter)", value=DEFAULT_MODEL)
    embed_name  = st.text_input("Embedding model", value=EMBED_MODEL_NAME)
    device_opt  = st.selectbox("Embedding device", ["auto (cuda if available)", "cpu", "cuda"], index=0)
    st.caption("â€» OPENROUTER_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì‹œ LLM í˜¸ì¶œ í™œì„±í™”")
    api_key = os.environ.get("OPENROUTER_API_KEY", "")

    st.divider()
    st.subheader("ğŸ•˜ Recent (last 5)")
    if not st.session_state["history"]:
        st.caption("ìµœê·¼ Q&A ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for idx, item in enumerate(st.session_state["history"][:5]):
            q_short = textwrap.shorten(item["q"], width=60, placeholder=" â€¦")
            a_short = textwrap.shorten(item.get("a",""), width=70, placeholder=" â€¦") if item.get("a") else "(ìƒì„± ì—†ìŒ)"
            st.markdown(f'<div class="history-card"><div class="history-q">Q: {html.escape(q_short)}</div><div class="history-a">A: {html.escape(a_short)}</div></div>', unsafe_allow_html=True)
            if st.button("â†º ì´ ì§ˆë¬¸ ë¶ˆëŸ¬ì˜¤ê¸°", key=f"load_hist_{idx}"):
                st.session_state["pending_query"] = item["q"]
                st.rerun()


# -----------------------------
# â™»ï¸ ë¦¬ì†ŒìŠ¤ ë¡œë“œ (cache)
# -----------------------------
@st.cache_resource(show_spinner=True)
def load_embeddings(model_name: str, device_choice: str):
    # device ê²°ì •
    dev = "cpu"
    if device_choice == "cpu":
        dev = "cpu"
    elif device_choice == "cuda":
        dev = "cuda"
    else:
        # auto
        try:
            import torch
            dev = "cuda" if torch.cuda.is_available() else "cpu"
        except Exception:
            dev = "cpu"

    return HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs={"device": dev},
        encode_kwargs={"normalize_embeddings": True},
    )

# ğŸ”§ UnhashableParamError ëŒ€ì‘: í•´ì‹œ ë¶ˆê°€ ê°ì²´ëŠ” ì¸ìëª… ì•ì— '_'ë¡œ ì „ë‹¬
@st.cache_resource(show_spinner=True)
def load_vectorstore(persist_dir: str, _embeddings):
    return Chroma(persist_directory=persist_dir, embedding_function=_embeddings, collection_name="amore_v1")

@st.cache_resource(show_spinner=True)
def build_chain(model_name: str, temperature: float, base_url: str, api_key: str):
    prompt = ChatPromptTemplate.from_messages(
        [("system", SYSTEM_PROMPT), ("user", USER_PROMPT_TEMPLATE)]
    )
    llm = ChatOpenAI(
        model=model_name,
        temperature=temperature,
        base_url=base_url,
        api_key=api_key if api_key else "DUMMY",
    )
    parser = StrOutputParser()
    return prompt | llm | parser


# -----------------------------
# ğŸ”§ ìœ í‹¸: ë¬¸ì„œ ì¹´ë“œ ë Œë”ë§
# -----------------------------
def _clean_filename(name: str) -> str:
    if not name:
        return "unknown"
    return unquote(name).replace("+", " ")

def parse_summary_and_figures(text: str):
    """ë¬¸ì„œ í…ìŠ¤íŠ¸ì—ì„œ 'í•µì‹¬ìš”ì•½:', 'í•µì‹¬ìˆ˜ì¹˜' íŒ¨í„´ì„ ì°¾ì•„ ì •ëˆ.
       ì¤„ ë§¨ ì• ë²ˆí˜¸(ì˜ˆ: '1) ')ë§Œ ì œê±°í•˜ê³ , í•„ë“œ ê°’ì€ ê±´ë“œë¦¬ì§€ ì•ŠëŠ”ë‹¤."""
    if not text:
        return [], []

    lines = [l.strip() for l in text.splitlines() if l.strip()]
    summary_items, figure_rows = [], []

    # 'í•µì‹¬ìš”ì•½' ìˆ˜ì§‘
    in_summary = False
    for ln in lines:
        if ln.startswith("í•µì‹¬ìš”ì•½"):
            in_summary = True
            after = ln.split(":", 1)[1].strip() if ":" in ln else ""
            if after:
                for piece in after.split(" - "):
                    p = piece.strip(" -")
                    if p:
                        summary_items.append(p)
            continue
        if in_summary:
            if ln.startswith("í•µì‹¬ìˆ˜ì¹˜") or ln.startswith("ë©”ëª¨"):
                in_summary = False
                continue
            if ln.startswith("-"):
                summary_items.append(ln.lstrip("- ").strip())

    # 'í•µì‹¬ìˆ˜ì¹˜' íŒŒì‹± (ë²ˆí˜¸ ì ‘ë‘ì–´ë§Œ ì œê±°)
    for ln in lines:
        if "ê°’:" in ln and "|" in ln:
            ln2 = re.sub(r'^\s*\d+\)\s*', '', ln)  # â† ì—¬ê¸°ë§Œ ë²ˆí˜¸ ì œê±°
            parts = [p.strip() for p in ln2.split("|")]

            row = {"ë¼ë²¨": "", "ê°’": "", "ë‹¨ìœ„": "", "ê¸°ê°„/ê¸°ì¤€": "", "ê·¼ê±°ì˜ì—­": ""}

            for p in parts:
                if ":" in p:
                    k, v = p.split(":", 1)
                    k = k.strip()
                    v = v.strip()  # ê°’ ì•ìë¦¬ ìˆ«ì ë³´ì¡´
                    if k in row:
                        row[k] = v

            if row.get("ë¼ë²¨") or row.get("ê°’"):
                figure_rows.append(row)

    return summary_items[:5], figure_rows[:5]

def format_doc(doc, idx=None):
    meta = doc.metadata or {}
    src  = meta.get("source") or meta.get("file") or meta.get("path") or "unknown"
    page = meta.get("page_number") or meta.get("page") or "N/A"
    txt  = (doc.page_content or "").strip()
    head = f"[{idx}] {os.path.basename(src)} (p.{page})" if idx is not None else f"{os.path.basename(src)} (p.{page})"
    body = textwrap.shorten(txt, width=500, placeholder=" â€¦")
    return head, body, meta

def render_doc_card(idx, doc):
    _, _, meta = format_doc(doc, idx)
    fname = _clean_filename(meta.get("source") or meta.get("file") or meta.get("path") or "unknown")
    page  = meta.get("page_number") or meta.get("page") or "N/A"
    lvl1  = meta.get("level1")
    lvl2  = meta.get("level2")

    summary_items, figure_rows = parse_summary_and_figures(doc.page_content or "")

    tags_html = '<div class="doc-tags">'
    tags_html += f'<span class="filepill">{html.escape(fname)}</span>'
    if lvl1: tags_html += f' <span class="badge">{html.escape(str(lvl1))}</span>'
    if lvl2: tags_html += f' <span class="badge">{html.escape(str(lvl2))}</span>'
    tags_html += f' <span class="badge">p.{html.escape(str(page))}</span></div>'

    # ìš”ì•½ bullets
    if summary_items:
        items_html = "".join([f"<li>{html.escape(it)}</li>" for it in summary_items])
        sum_html = f'<ul class="sum-list">{items_html}</ul>'
    else:
        sum_html = '<div class="small">ìš”ì•½ ì •ë³´ ì—†ìŒ</div>'

    # í•µì‹¬ìˆ˜ì¹˜ í‘œ (ë¼ë²¨ ì»¬ëŸ¼ ì œê±°)
    if figure_rows:
        header = "<tr><th>ê°’</th><th>ë‹¨ìœ„</th><th>ê¸°ê°„/ê¸°ì¤€</th><th>ê·¼ê±°ì˜ì—­</th></tr>"
        rows = ""
        for r in figure_rows:
            rows += (
                "<tr>"
                f"<td>{html.escape(r.get('ê°’',''))}</td>"
                f"<td>{html.escape(r.get('ë‹¨ìœ„',''))}</td>"
                f"<td>{html.escape(r.get('ê¸°ê°„/ê¸°ì¤€',''))}</td>"
                f"<td>{html.escape(r.get('ê·¼ê±°ì˜ì—­',''))}</td>"
                "</tr>"
            )
        fig_html = f'<table class="kv-table">{header}{rows}</table>'
    else:
        fig_html = '<div class="small">í•µì‹¬ ìˆ˜ì¹˜ ì—†ìŒ</div>'

    html_block = (
        f'<div class="doc-card">'
        f'<div class="doc-head">[{idx}] {html.escape(fname)} <span class="small">(p.{html.escape(str(page))})</span></div>'
        f'{tags_html}'
        f'<div class="small" style="margin-top:4px;"><b>í•µì‹¬ìš”ì•½</b></div>'
        f'{sum_html}'
        f'<div class="small" style="margin-top:8px;"><b>í•µì‹¬ìˆ˜ì¹˜</b></div>'
        f'{fig_html}'
        f'</div>'
    )
    st.markdown(html_block, unsafe_allow_html=True)


# -----------------------------
# ğŸ”„ ìœ„ì ¯ ìƒì„± ì „ í”„ë¦¬í•„ ì²˜ë¦¬
# -----------------------------
if st.session_state.get("pending_query"):
    st.session_state["user_query"] = st.session_state.pop("pending_query")

# -----------------------------
# ğŸ” ê²€ìƒ‰ + ìƒì„±
# -----------------------------
query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="user_query")
col1, col2, col3 = st.columns([1,1,1])
with col1:
    run_btn = st.button("Ask", type="primary")
with col2:
    clear_btn = st.button("Clear (ì´ í™”ë©´ë§Œ)")
with col3:
    clear_hist = st.button("Recent ë¹„ìš°ê¸°")

if clear_btn:
    st.session_state["answer"] = ""
    st.session_state["retrieved_docs"] = []
    st.session_state["user_query"] = ""
    st.rerun()

if clear_hist:
    st.session_state["history"] = []
    st.rerun()

# ì œì•ˆ ì§ˆë¬¸ 3ê°œ
def make_suggestions(q: str, docs):
    suggestions = []
    if q:
        suggestions.append(f"â€˜{q}â€™ì— ëŒ€í•œ í•µì‹¬ ê·¼ê±°ë§Œ í•­ëª©ë³„ë¡œ ìš”ì•½í•´ì¤˜")
        suggestions.append(f"â€˜{q}â€™ì™€ ê´€ë ¨ëœ ë°˜ëŒ€ ê´€ì ì´ë‚˜ ì ì¬ ë¦¬ìŠ¤í¬ëŠ” ë­ê°€ ìˆì–´?")
    src_name = None
    for d in (docs or []):
        meta = d.metadata or {}
        src  = meta.get("source") or meta.get("file") or meta.get("path")
        if src:
            src_name = os.path.basename(src)
            break
    if src_name:
        suggestions.append(f"{src_name} ë¬¸ì„œ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì²´ ì‚¬ë¡€/ìˆ˜ì¹˜ë¥¼ ë½‘ì•„ì¤˜")
    else:
        suggestions.append("ê´€ë ¨ ì§€í‘œ/ìˆ˜ì¹˜ë¥¼ í‘œë¡œ ì •ë¦¬í•´ì¤˜")
    uniq = []
    for s in suggestions:
        if s not in uniq:
            uniq.append(s)
        if len(uniq) == 3:
            break
    return uniq

suggestions = make_suggestions(st.session_state.get("user_query",""), st.session_state.get("retrieved_docs", []))
with st.container():
    st.markdown('<div class="suggest-box"><b>í˜¹ì‹œ ì´ëŸ°ê²Œ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?</b></div>', unsafe_allow_html=True)
    scols = st.columns(3)
    for i, s in enumerate(suggestions):
        if s is None:
            continue
        if scols[i].button(f"ğŸ§© {s}", key=f"sugg_{i}"):
            st.session_state["pending_query"] = s
            st.rerun()

if run_btn:
    if not os.path.isdir(chroma_dir):
        st.error(f"Chroma ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {chroma_dir}")
        st.stop()

    # Embeddings / Vectorstore
    with st.spinner("ì„ë² ë”©/ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì¤‘â€¦"):
        embeddings = load_embeddings(embed_name, device_opt)
        try:
            db = load_vectorstore(chroma_dir, embeddings)
        except Exception as e:
            st.exception(e)
            st.stop()

    # ê°„ë‹¨ í†µê³„(ì»¬ë ‰ì…˜ ë¬¸ì„œ ìˆ˜)
    try:
        count = db._collection.count()
        st.markdown(f'<div class="stat">ğŸ“¦ í˜„ì¬ ì»¬ë ‰ì…˜ ë¬¸ì„œ ìˆ˜: <b>{count}</b></div>', unsafe_allow_html=True)
    except Exception:
        pass

    retriever = db.as_retriever(search_kwargs={"k": top_k})

    with st.spinner("ê²€ìƒ‰ ì¤‘â€¦"):
        docs = retriever.invoke(query) if query.strip() else []
        st.session_state["retrieved_docs"] = docs

    # context ë§Œë“¤ê¸°
    ctx_chunks, src_list = [], []
    for i, d in enumerate(docs, start=1):
        h, b, m = format_doc(d, i)
        ctx_chunks.append(f"{h}\n{b}")
        src = m.get("source") or m.get("file") or m.get("path") or "unknown"
        if src:
            src_list.append(os.path.basename(src))
    context_text = "\n\n---\n\n".join(ctx_chunks) if ctx_chunks else "N/A"

    # LLM í˜¸ì¶œ
    answer_text = ""
    if not api_key:
        st.info("OPENROUTER_API_KEYê°€ ì—†ì–´ LLM í˜¸ì¶œì„ ìƒëµí•©ë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
    else:
        chain = build_chain(model_name, temperature, OPENROUTER_BASE_URL, api_key)
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘â€¦"):
            answer_text = chain.invoke({"context": context_text, "question": query}) or ""

    st.session_state["answer"] = answer_text

    # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸(ë§¨ ì•ì— ì¶”ê°€, 5ê°œ ìœ ì§€)
    hist = st.session_state["history"]
    hist.insert(0, {
        "q": query,
        "a": answer_text,
        "k": top_k,
        "sources": list(dict.fromkeys(src_list))[:5],
    })
    st.session_state["history"] = hist[:5]
    st.rerun()


# -----------------------------
# ğŸ§  ë‹µë³€ í‘œì‹œ
# -----------------------------
if st.session_state.get("answer"):
    st.markdown('<div class="chip">Answer</div>', unsafe_allow_html=True)
    st.markdown(f'<div class="answer-card">{st.session_state["answer"]}</div>', unsafe_allow_html=True)

# -----------------------------
# ğŸ“š ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
# -----------------------------
if "retrieved_docs" in st.session_state:
    st.markdown("### ğŸ“š ì°¸ê³  ë¬¸ì„œ")
    docs = st.session_state["retrieved_docs"]
    if not docs:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (DBê°€ ë¹„ì–´ìˆê±°ë‚˜, ì¿¼ë¦¬ì™€ ë¬¸ì„œê°€ ëœ ìœ ì‚¬í•  ìˆ˜ ìˆì–´ìš”)")
    else:
        for i, d in enumerate(docs, start=1):
            render_doc_card(i, d)
