# streamlit_rag_app.py

import os
import re
import sys
import shutil
import subprocess
import textwrap
import html
from time import sleep
from datetime import datetime
from urllib.parse import unquote
import warnings
import gc
from contextlib import contextmanager

import streamlit as st
from pathlib import Path
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import tempfile
import json
import chromadb  # Chroma 1.x client

# ===== ì „ì—­ ì•ˆì •í™”: ê²½ê³ /ìŠ¤ë ˆë“œ ì–µì œ =====
warnings.filterwarnings("ignore", category=DeprecationWarning)
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")
os.environ.setdefault("OMP_NUM_THREADS", "1")
os.environ.setdefault("OPENBLAS_NUM_THREADS", "1")
os.environ.setdefault("MKL_NUM_THREADS", "1")


@contextmanager
def guard(title: str = "ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."):
    """ì—ëŸ¬ë¥¼ íŒ¨ë„ë¡œ ë³´ì—¬ì£¼ê³  ì•ˆì „ ì¢…ë£Œ(st.stop)í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸"""
    try:
        yield
    except SystemExit:
        raise
    except Exception as e:
        # âœ… Streamlit ì¬ì‹¤í–‰ìš© ì˜ˆì™¸ëŠ” ê·¸ëƒ¥ í†µê³¼ì‹œì¼œì•¼ í•¨
        if e.__class__.__name__ == "RerunException":
            raise
        st.error(title)
        st.exception(e)
        st.stop()


# -----------------------------
# ğŸ”§ ê¸°ë³¸ ì„¤ì •
# -----------------------------
try:
    BASE_DIR = Path(__file__).resolve().parent
except NameError:
    BASE_DIR = Path.cwd()

# temp í´ë”(ë‹¨ì¼ ì‚¬ìš©ì ì „ì œ) + í¬ì¸í„° ë°©ì‹
DEFAULT_CHROMA_DIR = str(Path(tempfile.gettempdir()) / "chroma_store")  # /tmp/chroma_store
DEFAULT_MODEL       = "google/gemma-2-9b-it"
EMBED_MODEL_NAME    = "nlpai-lab/KURE-v1"
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"

SYSTEM_PROMPT = """You are a precise RAG assistant. Use ONLY the provided context.
If the answer is not in the context, say you don't know briefly.
Answer in Korean.
"""

USER_PROMPT_TEMPLATE = """[Context]
{context}

[Question]
{question}

[Instructions]
- Keep the answer concise but complete (â‰¤ 5 sentences).
"""

# -----------------------------
# ğŸ”§ í¬ì¸í„° ìœ í‹¸
# -----------------------------
def _pointer_file(root: str) -> Path:
    return Path(root) / "CURRENT.txt"

def _resolve_store_path(root: str) -> Path | None:
    p = _pointer_file(root)
    if not p.exists():
        return None
    try:
        sp = p.read_text(encoding="utf-8").strip()
    except Exception:
        return None
    return Path(sp) if sp and Path(sp).exists() else None

# -----------------------------
# ğŸ“… ë‚ ì§œ ì¶”ì¶œ ìœ í‹¸(íŒŒì¼ëª…/ë³¸ë¬¸/ìš”ì•½)
# -----------------------------
_DATE_PATTERNS = [
    re.compile(r"\((\d{4})[.\-/](\d{1,2})[.\-/](\d{1,2})\)"),     # (YYYY-MM-DD)
    re.compile(r"(\d{4})[.\-/](\d{1,2})[.\-/](\d{1,2})"),         # YYYY-MM-DD / YYYY.MM.DD / YYYY/MM/DD
    re.compile(r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼"), # YYYYë…„ MMì›” DDì¼
    re.compile(r"(20\d{2})(\d{2})(\d{2})"),                       # YYYYMMDD
    re.compile(r"(\d{4})[.\-/](\d{1,2})"),                        # YYYY-MM
    re.compile(r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”"),                 # YYYYë…„ MMì›”
    re.compile(r"(20\d{2})\s*ë…„"),                                # YYYYë…„
    re.compile(r"(?<!\d)(20\d{2})(?!\d)"),                        # YYYY
]

_HALF_RE    = re.compile(r"(20\d{2})\s*(ìƒë°˜ê¸°|í•˜ë°˜ê¸°|H[12])", re.IGNORECASE)
_QUARTER_RE = re.compile(r"(20\d{2})\s*(?:Q([1-4])|([1-4])\s*ë¶„ê¸°)", re.IGNORECASE)

def _mk_date(y, m=1, d=1) -> datetime | None:
    try:
        y, m, d = int(y), int(m), int(d)
        if not (1 <= m <= 12): m = 1
        if not (1 <= d <= 31): d = 1
        return datetime(y, m, d)
    except Exception:
        try:
            return datetime(int(y), int(m), 1)
        except Exception:
            return None

def _extract_dates_from_text(s: str) -> list[datetime]:
    if not s:
        return []
    out: list[datetime] = []
    for pat in _DATE_PATTERNS:
        for m in pat.finditer(s):
            g = m.groups()
            if len(g) >= 3:
                dt = _mk_date(g[0], g[1], g[2])
            elif len(g) == 2:
                dt = _mk_date(g[0], g[1], 1)
            else:
                dt = _mk_date(g[0], 1, 1)
            if dt:
                out.append(dt)
    for m in _HALF_RE.finditer(s):
        y, tag = m.group(1), m.group(2).upper()
        month = 6 if tag in ("ìƒë°˜ê¸°", "H1") else 12
        dt = _mk_date(y, month, 1)
        if dt:
            out.append(dt)
    for m in _QUARTER_RE.finditer(s):
        y = m.group(1)
        q = m.group(2) or m.group(3)
        try:
            qi = int(q)
        except Exception:
            continue
        month = {1: 3, 2: 6, 3: 9, 4: 12}.get(qi, 12)
        dt = _mk_date(y, month, 1)
        if dt:
            out.append(dt)
    return out

# -----------------------------
# ğŸ”§ ìœ í‹¸: ë Œë” í•¨ìˆ˜/íŒŒì„œ
# -----------------------------
def _clean_filename(name: str) -> str:
    if not name:
        return "unknown"
    return unquote(name).replace("+", " ")

def parse_summary_and_figures(text: str):
    if not text:
        return [], []
    lines = [l.strip() for l in text.splitlines() if l.strip()]
    summary_items, figure_rows = [], []
    in_summary = False

    for ln in lines:
        if ln.startswith("í•µì‹¬ìš”ì•½"):
            in_summary = True
            after = ln.split(":", 1)[1].strip() if ":" in ln else ""
            if after:
                for piece in after.split(" - "):
                    p = piece.strip(" -")
                    if p:
                        summary_items.append(p)
            continue
        if in_summary:
            if ln.startswith("í•µì‹¬ìˆ˜ì¹˜") or ln.startswith("ë©”ëª¨"):
                in_summary = False
                continue
            if ln.startswith("-"):
                summary_items.append(ln.lstrip("- ").strip())

    for ln in lines:
        if "ê°’:" in ln and "|" in ln:
            ln2 = re.sub(r'^\s*\d+\)\s*', '', ln)
            parts = [p.strip() for p in ln2.split("|")]
            row = {"ë¼ë²¨": "", "ê°’": "", "ë‹¨ìœ„": "", "ê¸°ê°„/ê¸°ì¤€": "", "ê·¼ê±°ì˜ì—­": ""}
            for p in parts:
                if ":" in p:
                    k, v = p.split(":", 1)
                    k = k.strip(); v = v.strip()
                    if k in row:
                        row[k] = v
            if row.get("ë¼ë²¨") or row.get("ê°’"):
                figure_rows.append(row)
    return summary_items[:5], figure_rows[:5]

# ìš”ì•½/ë³¸ë¬¸/íŒŒì¼ëª… ìˆœìœ¼ë¡œ ë‚ ì§œ ìš°ì„ ìˆœìœ„ í‰ê°€
def get_doc_date_info(doc) -> tuple[int, datetime | None]:
    """
    return (rank, dt)
      rank: 0=summary, 1=text, 2=source(path), 3=none
    """
    meta = getattr(doc, "metadata", {}) or {}
    src  = meta.get("source") or meta.get("file") or meta.get("path") or ""
    txt  = (getattr(doc, "page_content", "") or "")

    # 1) í•µì‹¬ìš”ì•½ì—ì„œ ë‚ ì§œ ì¶”ì¶œ (ìµœìš°ì„ )
    summary_items, _ = parse_summary_and_figures(txt)
    summary_text = " ".join(summary_items) if summary_items else ""
    cands_sum = _extract_dates_from_text(summary_text)
    if cands_sum:
        return (0, max(cands_sum))

    # 2) ë³¸ë¬¸ ì „ì²´ì—ì„œ ì¶”ì¶œ
    cands_txt = _extract_dates_from_text(txt)
    if cands_txt:
        return (1, max(cands_txt))

    # 3) íŒŒì¼ëª…/ê²½ë¡œì—ì„œ ì¶”ì¶œ
    cands_src = _extract_dates_from_text(src)
    if cands_src:
        return (2, max(cands_src))

    # 4) ì—†ìŒ
    return (3, None)

def get_doc_datetime(doc) -> datetime | None:
    return get_doc_date_info(doc)[1]

def _fmt_dt(dt: datetime | None) -> str:
    if not dt:
        return ""
    if dt.day != 1:
        return dt.strftime("%Y-%m-%d")
    if dt.month != 1:
        return dt.strftime("%Y-%m")
    return dt.strftime("%Y")

def format_doc(doc, idx=None):
    meta = getattr(doc, "metadata", {}) or {}
    src  = meta.get("source") or meta.get("file") or meta.get("path") or "unknown"
    page = meta.get("page_number") or meta.get("page") or "N/A"
    txt  = (getattr(doc, "page_content", "") or "").strip()
    head = f"[{idx}] {os.path.basename(src)} (p.{page})" if idx is not None else f"{os.path.basename(src)} (p.{page})"
    body = textwrap.shorten(txt, width=500, placeholder=" â€¦")
    return head, body, meta

def render_doc_card(idx, doc):
    head, body, meta = format_doc(doc, idx)
    fname = _clean_filename(meta.get("source") or meta.get("file") or meta.get("path") or "unknown")
    page  = meta.get("page_number") or meta.get("page") or "N/A"
    lvl1  = meta.get("level1")
    lvl2  = meta.get("level2")
    summary_items, figure_rows = parse_summary_and_figures(getattr(doc, "page_content", "") or "")
    dt    = get_doc_datetime(doc)
    dt_badge = _fmt_dt(dt)

    if summary_items:
        items_html = "".join([f"<li>{html.escape(it)}</li>" for it in summary_items])
        sum_html = f'<ul class="sum-list">{items_html}</ul>'
    else:
        sum_html = '<div class="small">ìš”ì•½ ì •ë³´ ì—†ìŒ</div>'

    if figure_rows:
        header = "<tr><th>ê°’</th><th>ë‹¨ìœ„</th><th>ê¸°ê°„/ê¸°ì¤€</th><th>ê·¼ê±°ì˜ì—­</th></tr>"
        rows = ""
        for r in figure_rows:
            rows += (
                "<tr>"
                f"<td>{html.escape(r.get('ê°’',''))}</td>"
                f"<td>{html.escape(r.get('ë‹¨ìœ„',''))}</td>"
                f"<td>{html.escape(r.get('ê¸°ê°„/ê¸°ì¤€',''))}</td>"
                f"<td>{html.escape(r.get('ê·¼ê±°ì˜ì—­',''))}</td>"
                "</tr>"
            )
        fig_table = f'<table class="kv-table">{header}{rows}</table>'
        fig_html = (
            "<details>"
            "<summary class='small' style='cursor:pointer;'>í•µì‹¬ìˆ˜ì¹˜ ë³´ê¸°</summary>"
            f"{fig_table}"
            "</details>"
        )
    else:
        fig_html = '<div class="small">í•µì‹¬ ìˆ˜ì¹˜ ì—†ìŒ</div>'

    tags_html = '<div class="doc-tags">'
    tags_html += f'<span class="filepill">{html.escape(fname)}</span>'
    if lvl1: tags_html += f' <span class="badge">{html.escape(str(lvl1))}</span>'
    if lvl2: tags_html += f' <span class="badge">{html.escape(str(lvl2))}</span>'
    tags_html += f' <span class="badge">p.{html.escape(str(page))}</span>'
    if dt_badge:
        tags_html += f' <span class="badge">{html.escape(dt_badge)}</span>'
    tags_html += '</div>'

    html_block = (
        f'<div class="doc-card">'
        f'<div class="doc-head">[{idx}] {html.escape(fname)} <span class="small">(p.{html.escape(str(page))})</span></div>'
        f'{tags_html}'
        f'<div class="small" style="margin-top:4px;"><b>í•µì‹¬ìš”ì•½</b></div>'
        f'{sum_html}'
        f'<div class="small" style="margin-top:8px;"><b>í•µì‹¬ìˆ˜ì¹˜</b></div>'
        f'{fig_html}'
        f'</div>'
    )
    st.markdown(html_block, unsafe_allow_html=True)

# -----------------------------
# ğŸ¨ í˜ì´ì§€ ìŠ¤íƒ€ì¼
# -----------------------------
st.set_page_config(page_title="RAG Q&A", page_icon="ğŸ”", layout="wide")

CUSTOM_CSS = """
<style>
header {visibility: hidden;}
.answer-card { border-radius: 16px; padding: 18px 20px; background: #ffffff;
  border: 1px solid rgba(0,0,0,0.08); box-shadow: 0 6px 20px rgba(0,0,0,0.06); }
.chip { display:inline-block; padding:4px 10px; border-radius:999px; background:#eef2ff;
  color:#3949ab; font-weight:600; font-size:12px; margin-bottom:6px; }
.doc-card { border-radius: 14px; padding: 12px 14px; background:#fafafa; border:1px solid #eee; margin-bottom:12px; }
.doc-head {font-weight:700; font-size:14px;}
.doc-body {font-size:13px; color:#333;}
.small {color:#666; font-size:12px;}
.footer {color:#777; font-size:12px; margin-top:8px;}
.stat {color:#444; font-size:13px; margin-bottom:6px;}
.history-card { border-radius: 12px; padding:10px 12px; background:#f6f7fb; border:1px solid #e6e8f5; margin-bottom:8px; }
.history-q {font-weight:700; font-size:13px;}
.history-a {font-size:12px; color:#555; margin-top:4px;}
.suggest-box {margin-top:8px; padding:10px 12px; background:#f9fafb; border:1px dashed #d7dbe2; border-radius:12px;}
.doc-tags {margin:6px 0 8px 0}
.badge {display:inline-block; padding:2px 8px; border-radius:999px; background:#eef2ff; color:#3949ab; font-size:11px; margin-right:6px;}
.filepill {display:inline-block; padding:2px 8px; background:#f1f5ff; border:1px solid #dfe6ff; color:#2146b7; border-radius:8px; font-weight:600;}
.sum-list {margin:6px 0 0 0; padding-left:18px;}
.kv-table {width:100%; border-collapse:collapse; margin-top:8px; font-size:12px;}
.kv-table th, .kv-table td {border:1px solid #e9e9ef; padding:6px 8px; text-align:left;}
.kv-table th {background:#f6f7fb; font-weight:700;}
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

st.title("ğŸ” RAG Q&A")
st.caption("03_RAG íŒŒì´í”„ë¼ì¸ì„ Streamlit UIë¡œ â€” LangChain + Chroma + OpenRouter")

# -----------------------------
# ğŸ—‚ï¸ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -----------------------------
for key, default in {
    "history": [],
    "retrieved_docs": [],
    "answer": "",
    "user_query": "",
    "pending_query": None,
    "db_built": False,
}.items():
    if key not in st.session_state:
        st.session_state[key] = default

# -----------------------------
# ğŸ§° ì‚¬ì´ë“œë°”
# -----------------------------
with st.sidebar:
    st.subheader("Settings")

    chroma_dir  = st.text_input("Chroma root directory (pointer)", value=DEFAULT_CHROMA_DIR)
    pkl_path    = st.text_input("PKL ê²½ë¡œ(ìƒ˜í”Œ)", value=str(BASE_DIR / "data" / "df_sample_pages.pkl"))

    top_k       = st.slider("Top-K (retrieval)", 1, 10, 3)
    temperature = st.slider("LLM Temperature", 0.0, 1.0, 0.2)
    model_name  = st.text_input("LLM (OpenRouter)", value=DEFAULT_MODEL)
    embed_name  = st.text_input("Embedding model", value=EMBED_MODEL_NAME)
    device_opt  = st.selectbox("Embedding device", ["cpu", "auto (cuda if available)", "cuda"], index=0)

    st.caption("â€» OPENROUTER_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì‹œ LLM í˜¸ì¶œ í™œì„±í™”")
    api_key = os.environ.get("OPENROUTER_API_KEY", "")

    st.divider()
    st.subheader("Index")
    rebuild_on_start = st.checkbox("ì•± ì‹œì‘ ì‹œ ê°•ì œ ì¬ìƒì„±", value=False)
    rebuild_now = st.button("ğŸ”¨ ì¸ë±ìŠ¤ ì¬ìƒì„± (ìˆ˜ë™)")

    st.divider()
    st.subheader("ğŸ•˜ Recent (last 5)")
    if not st.session_state["history"]:
        st.caption("ìµœê·¼ Q&A ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for idx, item in enumerate(st.session_state["history"][:5]):
            q_short = textwrap.shorten(item["q"], width=60, placeholder=" â€¦")
            a_short = textwrap.shorten(item.get("a",""), width=70, placeholder=" â€¦") if item.get("a") else "(ìƒì„± ì—†ìŒ)"
            st.markdown(
                f'<div class="history-card"><div class="history-q">Q: {html.escape(q_short)}</div>'
                f'<div class="history-a">A: {html.escape(a_short)}</div></div>',
                unsafe_allow_html=True
            )
            if st.button("â†º ì´ ì§ˆë¬¸ ë¶ˆëŸ¬ì˜¤ê¸°", key=f"load_hist_{idx}"):
                st.session_state["pending_query"] = item["q"]
                st.rerun()

# -----------------------------
# ğŸ§± DB ì¬ìƒì„± ìœ í‹¸ (ì‹¤ì‹œê°„ ë¡œê·¸/í¬ì¸í„° ê°±ì‹ )
# -----------------------------
def _device_arg(choice: str) -> str:
    if choice.startswith("auto"):
        return "auto"
    return choice

def rebuild_db_always(pkl_path: str, chroma_dir: str, collection: str, embed_model: str, device_choice: str):
    try:
        st.cache_resource.clear()
    except Exception:
        pass

    vs_script = Path(__file__).resolve().parent / "02_Vectorstore.py"
    if not vs_script.is_file():
        raise FileNotFoundError(f"02_Vectorstore.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {vs_script}")

    env = os.environ.copy()
    env.pop("CHROMA_DB_IMPL", None)
    env["TOKENIZERS_PARALLELISM"] = "false"

    cmd = [
        sys.executable, str(vs_script),
        "--root", chroma_dir,
        "--collection", collection,
        "--embed_model", embed_model,
        "--device", _device_arg(device_choice),
        "--pkl", pkl_path,
    ]
    cmd_str = " ".join(cmd)

    use_status = hasattr(st, "status")
    log_box = st.empty()

    def _append_log(lines, new_line):
        lines.append(new_line.rstrip())
        pre = "<pre style='max-height:280px;overflow:auto;'>" + html.escape("\n".join(lines[-300:])) + "</pre>"
        log_box.markdown(pre, unsafe_allow_html=True)

    if use_status:
        with st.status("ì´ˆê¸° ë²¡í„° DB ì¬ìƒì„± ì¤‘â€¦(í¬ì¸í„° ê°±ì‹ )", expanded=True) as status:
            status.write("1) ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
            status.write(f"2) ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: `{cmd_str}`")

            lines = []
            proc = subprocess.Popen(
                cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                text=True, bufsize=1, env=env
            )
            for line in proc.stdout:
                _append_log(lines, line)
            rc = proc.wait()

            if rc != 0:
                out_str = "\n".join(lines)
                status.update(state="error", label="ë¹Œë“œ ì‹¤íŒ¨")
                raise RuntimeError("02_Vectorstore ì‹¤í–‰ ì‹¤íŒ¨\nCMD: " + cmd_str + "\nSTDOUT/ERR:\n" + out_str)

            status.write("3) í¬ì¸í„°(CURRENT.txt) ê°±ì‹  í™•ì¸ ì¤‘â€¦")
            pointer = Path(chroma_dir) / "CURRENT.txt"
            if not pointer.exists():
                status.update(state="error", label="í¬ì¸í„° íŒŒì¼ ëˆ„ë½")
                raise FileNotFoundError(f"í¬ì¸í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pointer}")

            store_path = pointer.read_text(encoding="utf-8").strip()
            if not store_path or not Path(store_path).exists():
                status.update(state="error", label="í¬ì¸í„° ê²½ë¡œ ë¶ˆëŸ‰")
                raise FileNotFoundError(f"í¬ì¸í„°ê°€ ê°€ë¦¬í‚¤ëŠ” ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤: {store_path}")

            status.update(state="complete", label="ì´ˆê¸° ë²¡í„° DB ì¬ìƒì„± ì™„ë£Œ")
            return True
    else:
        with st.spinner("ì´ˆê¸° ë²¡í„° DB ì¬ìƒì„± ì¤‘â€¦(í¬ì¸í„° ê°±ì‹ )"):
            lines = []
            proc = subprocess.Popen(
                cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                text=True, bufsize=1, env=env
            )
            for line in proc.stdout:
                _append_log(lines, line)
            rc = proc.wait()
            if rc != 0:
                out_str = "\n".join(lines)
                raise RuntimeError("02_Vectorstore ì‹¤í–‰ ì‹¤íŒ¨\nCMD: " + cmd_str + "\nSTDOUT/ERR:\n" + out_str)

            pointer = Path(chroma_dir) / "CURRENT.txt"
            if not pointer.exists():
                raise FileNotFoundError(f"í¬ì¸í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pointer}")

            store_path = pointer.read_text(encoding="utf-8").strip()
            if not store_path or not Path(store_path).exists():
                raise FileNotFoundError(f"í¬ì¸í„°ê°€ ê°€ë¦¬í‚¤ëŠ” ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤: {store_path}")

            st.success("ì´ˆê¸° ë²¡í„° DB ì¬ìƒì„± ì™„ë£Œ")
            return True

# -----------------------------
# ğŸ ì•± ì‹œì‘ ì‹œì : í¬ì¸í„° í™•ì¸ & ì„ íƒì  ì¬ë¹Œë“œ
# -----------------------------
with guard("ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."):
    pointer_ok = _resolve_store_path(
        DEFAULT_CHROMA_DIR if 'chroma_dir' not in st.session_state else st.session_state.get('chroma_dir', DEFAULT_CHROMA_DIR)
    ) is not None
    need_build = rebuild_on_start or (_resolve_store_path(DEFAULT_CHROMA_DIR) is None)

    if not st.session_state["db_built"]:
        if need_build:
            try:
                rebuild_db_always(
                    pkl_path=pkl_path,
                    chroma_dir=chroma_dir,
                    collection="amore_v1",
                    embed_model=EMBED_MODEL_NAME,
                    device_choice=device_opt
                )
                st.session_state["db_built"] = True
            except Exception as e:
                st.error("ì¸ë±ìŠ¤ ì¬ìƒì„± ì‹¤íŒ¨ â€” ì•„ë˜ ë¡œê·¸ í™•ì¸ í›„ í•„ìš” ì‹œ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                st.exception(e)
                if _resolve_store_path(chroma_dir) is None:
                    st.stop()
        else:
            st.session_state["db_built"] = True

    if rebuild_now:
        try:
            rebuild_db_always(
                pkl_path=pkl_path,
                chroma_dir=chroma_dir,
                collection="amore_v1",
                embed_model=EMBED_MODEL_NAME,
                device_choice=device_opt
            )
            st.success("ì¸ë±ìŠ¤ë¥¼ ì¬ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error("ì¸ë±ìŠ¤ ì¬ìƒì„± ì‹¤íŒ¨")
            st.exception(e)

# -----------------------------
# â™»ï¸ ë¦¬ì†ŒìŠ¤ ë¡œë“œ (cache)
# -----------------------------
def _normalize_device(dev_choice: str) -> str:
    if dev_choice.startswith("auto"):
        try:
            import torch
            return "cuda" if torch.cuda.is_available() else "cpu"
        except Exception:
            return "cpu"
    return dev_choice

@st.cache_resource(show_spinner=True)
def load_embeddings(model_name: str, device_choice: str):
    dev = _normalize_device(device_choice)
    return HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs={"device": dev},
        encode_kwargs={"normalize_embeddings": True},
    )

@st.cache_resource(show_spinner=True)
def load_vectorstore(persist_root: str, embed_model: str, device_choice: str, collection: str = "amore_v1"):
    emb = load_embeddings(embed_model, device_choice)

    pointer = Path(persist_root) / "CURRENT.txt"
    if not pointer.exists():
        raise FileNotFoundError(
            f"í¬ì¸í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pointer}\n"
            f"ì‚¬ì´ë“œë°”ì˜ 'ì¸ë±ìŠ¤ ì¬ìƒì„±'ìœ¼ë¡œ ë¨¼ì € ë§Œë“¤ì„¸ìš”."
        )
    store_path = pointer.read_text(encoding="utf-8").strip()
    if not store_path or not Path(store_path).exists():
        raise FileNotFoundError(
            f"í¬ì¸í„°ê°€ ê°€ë¦¬í‚¤ëŠ” ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤: {store_path}\n"
            f"ì‚¬ì´ë“œë°”ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ìƒì„±í•˜ì„¸ìš”."
        )

    client = chromadb.PersistentClient(path=store_path)  # 1.x ë°©ì‹
    db = Chroma(client=client, embedding_function=emb, collection_name=collection)
    return db, emb

@st.cache_resource(show_spinner=True)
def build_chain(model_name: str, temperature: float, base_url: str, api_key: str):
    prompt = ChatPromptTemplate.from_messages(
        [("system", SYSTEM_PROMPT), ("user", USER_PROMPT_TEMPLATE)]
    )
    llm = ChatOpenAI(
        model=model_name,
        temperature=temperature,
        base_url=base_url,
        api_key=api_key,
    )
    parser = StrOutputParser()
    return prompt | llm | parser

# -----------------------------
# ğŸ”„ ìœ„ì ¯ ìƒì„± ì „ í”„ë¦¬í•„ ì²˜ë¦¬
# -----------------------------
if st.session_state.get("pending_query"):
    st.session_state["user_query"] = st.session_state.pop("pending_query")

# -----------------------------
# ğŸ” ê²€ìƒ‰ + ìƒì„±
# -----------------------------
query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="user_query")

st.markdown(
    """
    <div class="suggest-box">
      <b>ì§ˆë¬¸ ì˜ˆ</b><br/>
      1. ì½”ë¡œë‚˜19 ì´í›„ ì†Œë¹„ì íŠ¸ë Œë“œì— ëŒ€í•´ ì•Œë ¤ì¤˜<br/>
      2. ê¸°ëŠ¥ì„± í™”ì¥í’ˆì˜ ì‹œì¥ ê·œëª¨ì™€ ì „ë§ì„ ì•Œë ¤ì¤˜<br/>
      3. 2024ë…„ ë·°í‹° ì‚°ì—… ì£¼ìš”íŠ¸ë Œë“œê°€ ë­ì•¼?
    </div>
    """,
    unsafe_allow_html=True
)

col1, col2, col3 = st.columns([1,1,1])
with col1:
    run_btn = st.button("Ask", type="primary")
with col2:
    clear_btn = st.button("Clear (ì´ í™”ë©´ë§Œ)")
with col3:
    clear_hist = st.button("Recent ë¹„ìš°ê¸°")

if clear_btn:
    st.session_state["answer"] = ""
    st.session_state["retrieved_docs"] = []
    st.session_state["user_query"] = ""
    st.session_state["_do_rerun"] = True

if clear_hist:
    st.session_state["history"] = []
    st.session_state["_do_rerun"] = True

def make_suggestions(q: str, docs):
    suggestions = []
    if q:
        suggestions.append(f"â€˜{q}â€™ì— ëŒ€í•œ í•µì‹¬ ê·¼ê±°ë§Œ í•­ëª©ë³„ë¡œ ìš”ì•½í•´ì¤˜")
        suggestions.append(f"â€˜{q}â€™ì™€ ê´€ë ¨ëœ ë°˜ëŒ€ ê´€ì ì´ë‚˜ ì ì¬ ë¦¬ìŠ¤í¬ëŠ” ë­ê°€ ìˆì–´?")
    src_name = None
    for d in (docs or []):
        meta = getattr(d, "metadata", {}) or {}
        src  = meta.get("source") or meta.get("file") or meta.get("path")
        if src:
            src_name = os.path.basename(src)
            break
    if src_name:
        suggestions.append(f"{os.path.basename(src_name)} ë¬¸ì„œ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì²´ ì‚¬ë¡€/ìˆ˜ì¹˜ë¥¼ ë½‘ì•„ì¤˜")
    else:
        suggestions.append("ê´€ë ¨ ì§€í‘œ/ìˆ˜ì¹˜ë¥¼ í‘œë¡œ ì •ë¦¬í•´ì¤˜")
    uniq = []
    for s in suggestions:
        if s not in uniq:
            uniq.append(s)
        if len(uniq) == 3:
            break
    return uniq

suggestions = make_suggestions(st.session_state.get("user_query",""), st.session_state.get("retrieved_docs", []))
with st.container():
    st.markdown('<div class="suggest-box"><b>í˜¹ì‹œ ì´ëŸ°ê²Œ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?</b></div>', unsafe_allow_html=True)
    scols = st.columns(3)
    for i, s in enumerate(suggestions):
        if s is None:
            continue
        # ì¶”ì²œ ì§ˆë¬¸ ë²„íŠ¼
        if scols[i].button(f"ğŸ§© {s}", key=f"sugg_{i}"):
            st.session_state["pending_query"] = s
            st.session_state["_do_rerun"] = True

with guard("ê²€ìƒ‰/ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."):
    if run_btn:
        with st.spinner("ì„ë² ë”©/ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì¤‘â€¦"):
            try:
                db, embeddings = load_vectorstore(chroma_dir, embed_name, device_opt, collection="amore_v1")
            except Exception as e:
                st.exception(e)
                st.stop()

        # ì„ë² ë”© ì°¨ì› ê²€ì¦
        try:
            qdim = len(embeddings.embed_query("ping"))
            pointer = Path(chroma_dir) / "CURRENT.txt"
            store_path = pointer.read_text(encoding="utf-8").strip() if pointer.exists() else None
            meta_f = os.path.join(store_path, "meta.json") if store_path else None
            if meta_f and os.path.exists(meta_f):
                with open(meta_f, "r", encoding="utf-8") as f:
                    meta = json.load(f)
                if "dim" in meta and meta["dim"] != qdim:
                    st.error(f"ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜: DB={meta['dim']} vs í˜„ì¬ ëª¨ë¸={qdim}. "
                             f"DB ìƒì„± ì‹œ ì‚¬ìš©í•œ ì„ë² ë”©ê³¼ ë™ì¼í•œ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.")
                    st.stop()
        except Exception as e:
            st.exception(e)
            st.stop()

        # ì»¬ë ‰ì…˜ ë¬¸ì„œ ìˆ˜
        try:
            count = db._collection.count()
            st.markdown(f'<div class="stat">ğŸ“¦ í˜„ì¬ ì»¬ë ‰ì…˜ ë¬¸ì„œ ìˆ˜: <b>{count}</b></div>', unsafe_allow_html=True)
            if count == 0:
                st.warning("Chroma ì»¬ë ‰ì…˜ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì¸ë±ì‹± ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        except Exception:
            pass

        retriever = db.as_retriever(search_kwargs={"k": top_k})

        with st.spinner("ê²€ìƒ‰ ì¤‘â€¦"):
            docs = retriever.invoke(query) if query.strip() else []
            st.session_state["retrieved_docs"] = docs

        # context ë§Œë“¤ê¸°
        ctx_chunks, src_list = [], []
        for i, d in enumerate(docs, start=1):
            head, body, meta = format_doc(d, i)
            ctx_chunks.append(f"{head}\n{body}")
            src = meta.get("source") or meta.get("file") or meta.get("path") or "unknown"
            if src:
                src_list.append(os.path.basename(src))
        context_text = "\n\n---\n\n".join(ctx_chunks) if ctx_chunks else "N/A"

        # LLM í˜¸ì¶œ
        answer_text = ""
        if not api_key:
            st.info("OPENROUTER_API_KEYê°€ ì—†ì–´ LLM í˜¸ì¶œì„ ìƒëµí•©ë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
        else:
            try:
                chain = build_chain(model_name, temperature, OPENROUTER_BASE_URL, api_key)
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘â€¦"):
                    answer_text = chain.invoke({"context": context_text, "question": query}) or ""
            except Exception as e:
                st.exception(e)
                answer_text = ""

        st.session_state["answer"] = answer_text

        # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        hist = st.session_state["history"]
        hist.insert(0, {"q": query, "a": answer_text, "k": top_k, "sources": list(dict.fromkeys(src_list))[:5]})
        st.session_state["history"] = hist[:5]
        st.session_state["_do_rerun"] = True    # âœ… í”Œë˜ê·¸ë§Œ
        

# -----------------------------
# ğŸ§  ë‹µë³€ í‘œì‹œ
# -----------------------------
if st.session_state.get("answer"):
    st.markdown('<div class="chip">Answer</div>', unsafe_allow_html=True)
    st.markdown(f'<div class="answer-card">{st.session_state["answer"]}</div>', unsafe_allow_html=True)

# -----------------------------
# ğŸ“š ì°¸ê³  ë¬¸ì„œ í‘œì‹œ (ìµœì‹ ìˆœ)
# -----------------------------
with guard("ì°¸ê³  ë¬¸ì„œ ë Œë”ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."):
    if "retrieved_docs" in st.session_state:
        st.markdown("### ğŸ“š ì°¸ê³  ë¬¸ì„œ")
        docs = st.session_state["retrieved_docs"]
        if not docs:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (DBê°€ ë¹„ì–´ìˆê±°ë‚˜, ì¿¼ë¦¬ì™€ ë¬¸ì„œê°€ ëœ ìœ ì‚¬í•  ìˆ˜ ìˆì–´ìš”)")
        else:
            # (date desc). ì˜¤ì§ ë‚ ì§œ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
            def _sort_key(d):
                _, dt = get_doc_date_info(d)  # rank ì •ë³´ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                ts = -dt.timestamp() if dt else 0  # ë‚ ì§œê°€ ìµœì‹ ì¼ìˆ˜ë¡ í° timestamp ê°’ì„ ê°€ì§€ë¯€ë¡œ, ìŒìˆ˜ë¡œ ë§Œë“¤ì–´ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (ê²°ê³¼ì ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ)
                return ts

            docs_sorted = sorted(docs, key=_sort_key)

            for i, d in enumerate(docs_sorted, start=1):
                render_doc_card(i, d)

# ---- ë§ˆì§€ë§‰ ì •ë¦¬(ë©”ëª¨ë¦¬ ì†ŒëŸ‰ íšŒìˆ˜) ----
try:
    gc.collect()
except Exception:
    pass

# âœ… ì—¬ê¸°ì„œë§Œ ì‹¤ì œ ì¬ì‹¤í–‰ íŠ¸ë¦¬ê±°
if st.session_state.pop("_do_rerun", False):
    st.rerun()
